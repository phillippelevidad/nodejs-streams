// Run this file second. It will generate a report from the data file
// generated by the previous step.
// -----

import fs, { createWriteStream } from "fs";
import { config } from "./config.js";

// Check if orders file exists
// ===========================

if (!fs.existsSync(config.ORDERS_FILE)) {
  console.error(`Orders file not found: ${config.ORDERS_FILE}`);
  console.error("Please run `npm run data` first");
  process.exit(1);
}

// Process orders
// ==============

import { performance } from "perf_hooks";
import { pipeline } from "stream/promises";
import split from "split2";

const startTime = performance.now();

const report = {
  grandTotal: 0,
  customers: {},
  months: {},
  categories: {},
};

// First step of the pipeline
// Read the orders file in chunks
const input = fs.createReadStream(config.ORDERS_FILE);

// Second step of the pipeline
// Split the orders into lines and parse each line as JSON
const splitAndParse = split(JSON.parse);

// Third step of the pipeline
// Aggregate the data
// Accumulate the report data in memory
async function* aggregate(stream) {
  for await (const data of stream) {
    report.grandTotal += data.orderTotal;

    report.customers[data.customer] =
      (report.customers[data.customer] ?? 0) + data.orderTotal;

    report.months[data.date.slice(0, 7)] =
      (report.months[data.date.slice(0, 7)] ?? 0) + data.orderTotal;

    for (const item of data.items) {
      report.categories[item.category] =
        (report.categories[item.category] ?? 0) +
        item.quantity * item.unitPrice;
    }
  }

  yield JSON.stringify(report, null, 2);
}

// Fourth step of the pipeline
// Write the report to a file
const output = createWriteStream(config.REPORT_FILE);

// Create a pipeline that will read the orders file, split it into lines,
// parse each line as JSON, aggregate the data and write the report to a file.
// This is a very efficient way of processing large amounts of data. Each order
// is processed as soon as it's read from the file, without having to
// accumulate all orders in memory.
await pipeline(input, splitAndParse, aggregate, output);

const endTime = performance.now();
console.log(`Report written to ${config.REPORT_FILE}`);
console.log(`Time taken: ${((endTime - startTime) / 1000).toFixed(2)}s`);
process.exit(0);
